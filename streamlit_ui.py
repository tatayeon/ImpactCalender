import pandas as pd
import streamlit as st
import yfinance as yf
from datetime import datetime
from streamlit_calendar import calendar
import os

from crawler import crawl_naver_view_titles
from rag_index import create_faiss_index
from rag_search import rag_query
from korea_dart_loader import get_corp_list, get_recent_disclosures , analyze_disclosure_with_rag

#########################################
# 1) ë¯¸êµ­ ìƒì¥ì£¼ ë¦¬ìŠ¤íŠ¸ ë¡œë“œ & í´ë¦° í•„í„°ë§
#########################################
@st.cache_data
def load_clean_us_symbols():
    """
    âœ… S&P500 + NASDAQ/NYSE ì „ì²´ ì‹¬ë³¼ ë¡œë“œ
    âœ… ETF, Test Issue ì œê±°
    âœ… BRK.A â†’ BRK-A ë³€í™˜
    âœ… ìºì‹± í›„ ì¬ì‹¤í–‰ ì‹œ ë¹ ë¥´ê²Œ ë¡œë“œ
    """
    cache_path = "data/clean_us_symbols.csv"
    if os.path.exists(cache_path):
        df = pd.read_csv(cache_path)
        return df["Symbol"].tolist()

    # --- 1) S&P500 ì‹¬ë³¼ ---
    sp500_url = "https://en.wikipedia.org/wiki/List_of_S%26P_500_companies"
    sp500_table = pd.read_html(sp500_url)[0]
    sp500_symbols = sp500_table["Symbol"].tolist()

    # --- 2) NASDAQ/NYSE/AMEX ---
    nasdaq_url = "ftp://ftp.nasdaqtrader.com/SymbolDirectory/nasdaqlisted.txt"
    other_url = "ftp://ftp.nasdaqtrader.com/SymbolDirectory/otherlisted.txt"

    try:
        df1 = pd.read_csv(nasdaq_url, sep="|")
        df2 = pd.read_csv(other_url, sep="|")

        # âœ… ETF / Test Issue ì œê±°
        df1_clean = df1[(df1["ETF"] == "N") & (df1["Test Issue"] == "N")]
        df2_clean = df2[(df2["Test Issue"] == "N")]

        # âœ… Symbol ì»¬ëŸ¼ í•©ì¹˜ê¸°
        all_symbols_raw = pd.concat([
            df1_clean["Symbol"],
            df2_clean["ACT Symbol"]
        ]).dropna().unique().tolist()
    except Exception as e:
        st.warning(f"âš ï¸ NASDAQ/NYSE ë¦¬ìŠ¤íŠ¸ ë¡œë“œ ì‹¤íŒ¨ â†’ {e}")
        all_symbols_raw = []

    # --- 3) yfinance í˜¸í™˜ ì‹¬ë³¼ ë³€í™˜ (. â†’ -)
    def normalize_symbol(sym):
        return sym.replace(".", "-").strip()

    sp500_symbols = [normalize_symbol(s) for s in sp500_symbols]
    all_symbols_raw = [normalize_symbol(s) for s in all_symbols_raw]

    # --- 4) í†µí•© & ì¤‘ë³µ ì œê±° ---
    combined = sorted(set(sp500_symbols + all_symbols_raw))

    # --- 5) ì´ìƒí•œ ì‹¬ë³¼ ì œê±° ---
    valid_symbols = [
        s for s in combined
        if (s.isalnum() or "-" in s) and 1 < len(s) <= 6
    ]

    # --- 6) ìºì‹± ---
    os.makedirs("data", exist_ok=True)
    pd.DataFrame({"Symbol": valid_symbols}).to_csv(cache_path, index=False)

    return valid_symbols

#########################################
# 2) yfinance íšŒì‚¬ëª… ê°€ì ¸ì˜¤ê¸°
#########################################
@st.cache_data
def fetch_company_names(symbols):
    """
    âœ… ì„ íƒëœ ì‹¬ë³¼ì˜ íšŒì‚¬ëª…(Long Name) ê°€ì ¸ì˜¤ê¸°
    """
    result = {}
    for sym in symbols:
        try:
            info = yf.Ticker(sym).info
            long_name = info.get("longName") or info.get("shortName") or "Unknown Company"
            result[sym] = long_name
        except Exception:
            result[sym] = "Unknown Company"
    return result

#########################################
# 3) yfinance ì–´ë‹ ì¼ì • ê°€ì ¸ì˜¤ê¸°
#########################################
def get_earnings_calendar(symbols):
    events = []
    for symbol in symbols:
        stock = yf.Ticker(symbol)
        info = stock.calendar

        if hasattr(info, "index") and "Earnings Date" in info.index:
            earnings_date_raw = info.loc["Earnings Date"][0]
            eps_estimate = (
                info.loc["Earnings Average"][0]
                if "Earnings Average" in info.index else "N/A"
            )
        elif isinstance(info, dict) and "Earnings Date" in info:
            earnings_date_raw = info["Earnings Date"]
            eps_estimate = info.get("Earnings Average", "N/A")
        else:
            continue

        if isinstance(earnings_date_raw, list) and len(earnings_date_raw) > 0:
            earnings_date = earnings_date_raw[0]
        else:
            earnings_date = earnings_date_raw

        if hasattr(earnings_date, "strftime"):
            earnings_date = earnings_date.strftime("%Y-%m-%d")
        elif not isinstance(earnings_date, str):
            earnings_date = str(earnings_date)

        events.append({
            "title": f"{symbol} ì–´ë‹ì½œ (EPS {eps_estimate})",
            "start": earnings_date,
            "symbol": symbol,
            "eps_estimate": eps_estimate
        })

    return events

#########################################################
# âœ… 5) Streamlit UI
#########################################################
st.title("ğŸ“Š ê¸€ë¡œë²Œ & í•œêµ­ ì£¼ì‹ ìº˜ë¦°ë”/ê³µì‹œ + ë‰´ìŠ¤ RAG")

tab1, tab2 = st.tabs(["ğŸŒ í•´ì™¸ ì£¼ì‹", "ğŸ‡°ğŸ‡· í•œêµ­ ì£¼ì‹"])

#########################
# ğŸŒ í•´ì™¸ ì£¼ì‹ íƒ­
#########################
with tab1:
    st.subheader("ğŸŒ í•´ì™¸ ì£¼ì‹ ì–´ë‹ ìº˜ë¦°ë” + ë‰´ìŠ¤ RAG")

    all_symbols = load_clean_us_symbols()
    #st.write(f"âœ… ì „ì²´ ë¯¸êµ­ ì£¼ì‹ {len(all_symbols)}ê°œ ë¡œë“œ ì™„ë£Œ!")

    user_symbols = st.multiselect(
        "ğŸ” ê´€ì‹¬ ìˆëŠ” í•´ì™¸ ì¢…ëª© ì„ íƒ",
        options=all_symbols,
        default=["AAPL", "MSFT", "TSLA"]
    )

    if user_symbols:
        company_names = fetch_company_names(user_symbols)
        st.subheader("âœ… ì„ íƒëœ ì¢…ëª© ë¦¬ìŠ¤íŠ¸")
        for sym in user_symbols:
            st.write(f"- {sym} ({company_names[sym]})")

    if st.button("ğŸ“† í•´ì™¸ ìº˜ë¦°ë” í‘œì‹œ"):
        earnings_events = get_earnings_calendar(user_symbols)
        st.session_state["calendar_events"] = earnings_events
        if not earnings_events:
            st.warning("âš ï¸ ì„ íƒí•œ ì¢…ëª©ì— ì–´ë‹ ì¼ì • ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. (yfinance ì œí•œ)")

    calendar_events = st.session_state.get("calendar_events", [])

    if calendar_events:
        st.subheader("ğŸ—“ ì–´ë‹ ì¼ì • ìº˜ë¦°ë”")
        calendar_options = {"initialView": "dayGridMonth", "selectable": True}
        calendar_return = calendar(events=calendar_events, options=calendar_options)

        if (
            calendar_return
            and "eventClick" in calendar_return
            and "event" in calendar_return["eventClick"]
        ):
            selected_event = calendar_return["eventClick"]["event"]
            symbol = selected_event["extendedProps"]["symbol"]

            company_name = fetch_company_names([symbol]).get(symbol, "")
            st.info(f"âœ… ì„ íƒí•œ ì¼ì •: {symbol} ({company_name}) | {selected_event['start']}")

            keyword = f"{symbol} {company_name}"
            query = f"{symbol} ({company_name}) ìµœê·¼ ì–´ë‹ì½œ ê´€ë ¨ íˆ¬ì í¬ì¸íŠ¸ ìš”ì•½í•´ì¤˜"

            if (
                "last_selected_symbol" not in st.session_state
                or st.session_state["last_selected_symbol"] != symbol
            ):
                with st.spinner(f"ğŸ“° {symbol} ë‰´ìŠ¤ í¬ë¡¤ë§ ë° RAG ë¶„ì„ ì¤‘..."):
                    crawl_naver_view_titles(keyword, limit=10)
                    create_faiss_index(keyword)
                    summary = rag_query(keyword, query)
                st.session_state["last_selected_symbol"] = symbol
                st.session_state["last_summary"] = summary

            if "last_summary" in st.session_state:
                st.success(f"ğŸ¤– ë¶„ì„ ê²°ê³¼:\n\n{st.session_state['last_summary']}")

#########################
# ğŸ‡°ğŸ‡· í•œêµ­ ì£¼ì‹ íƒ­
#########################
with tab2:
    st.subheader("ğŸ‡°ğŸ‡· í•œêµ­ ì‹¤ì ê³µì‹œ ìº˜ë¦°ë” + ë‰´ìŠ¤/ê³µì‹œ ê²°í•© RAG")

    # âœ… í•œêµ­ ìƒì¥ì‚¬ ë¦¬ìŠ¤íŠ¸ ë¶ˆëŸ¬ì˜¤ê¸°
    corp_df = get_corp_list()
    if corp_df.empty:
        st.warning("âš ï¸ í•œêµ­ ìƒì¥ì‚¬ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
    else:
        corp_names = corp_df["corp_name"].tolist()
        selected_corp = st.selectbox("ğŸ” ê²€ìƒ‰í•  í•œêµ­ ê¸°ì—…", corp_names)

        if selected_corp:
            corp_code = corp_df[corp_df["corp_name"] == selected_corp]["corp_code"].values[0]

            # âœ… â€˜ì‹¤ì  ê´€ë ¨ ê³µì‹œâ€™ ìº˜ë¦°ë” í‘œì‹œ
            if st.button("ğŸ“† í•œêµ­ ì‹¤ì ê³µì‹œ ìº˜ë¦°ë” í‘œì‹œ"):
                disclosures = get_recent_disclosures(corp_code)

                if disclosures:
                    events = []
                    for d in disclosures:
                        # YYYYMMDD â†’ YYYY-MM-DD ë³€í™˜
                        dt_fmt = f"{d['rcept_dt'][:4]}-{d['rcept_dt'][4:6]}-{d['rcept_dt'][6:]}"
                        events.append({
                            "title": f"{selected_corp} | {d['report_nm']}",
                            "start": dt_fmt,
                            "corp_name": selected_corp,
                            "report_nm": d["report_nm"],
                            "rcept_no": d["rcept_no"]
                        })
                    st.session_state["kr_events"] = events
                else:
                    st.warning("âš ï¸ ìµœê·¼ 90ì¼ê°„ ì‹¤ì  ê´€ë ¨ ê³µì‹œê°€ ì—†ìŠµë‹ˆë‹¤.")

    kr_events = st.session_state.get("kr_events", [])
    if kr_events:
        st.subheader("ğŸ—“ í•œêµ­ ì‹¤ì ê³µì‹œ ìº˜ë¦°ë”")
        cal_ret = calendar(events=kr_events, options={"initialView": "dayGridMonth"})

        # âœ… ìº˜ë¦°ë” í´ë¦­ â†’ ê³µì‹œ+ë‰´ìŠ¤ ê²°í•© RAG
        if cal_ret and "eventClick" in cal_ret and "event" in cal_ret["eventClick"]:
            evt = cal_ret["eventClick"]["event"]
            cname = evt["extendedProps"]["corp_name"]
            rname = evt["extendedProps"]["report_nm"]
            rno = evt["extendedProps"]["rcept_no"]

            st.info(f"âœ… {cname} | {rname} ë‰´ìŠ¤+ê³µì‹œ ë¶„ì„ ì‹¤í–‰ì¤‘...")
            with st.spinner("ê³µì‹œ+ë‰´ìŠ¤ ê²°í•© RAG ë¶„ì„ ì¤‘..."):
                summary = analyze_disclosure_with_rag(cname, rname, rno)
            st.success(summary)